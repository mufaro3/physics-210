{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75541d8f",
   "metadata": {},
   "source": [
    "Dear Allen Zhao,\n",
    "\n",
    "Thank you for your feedback on my Project 3 submission. Here are my responses. I hope that they are sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f8471",
   "metadata": {},
   "source": [
    "> This is quite a deviation from the array-based Monte Carlo framework we introduced in class. If you are intent on using this, I would like to see a straightforward comparison with the method we've laid out for you which makes it clear that your implementation is equivalent and robust enough for the purposes of this project.\n",
    "\n",
    "\n",
    "> One major concern I have is that you are currently only modeling 3--4 generations of neutrons, which might not be enough to give statistically sound results (you need to verify this). If you end up needing to iterate over many more generations, I am not sure how performant an exponentially-growing tree of Python objects will be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df54fb",
   "metadata": {},
   "source": [
    "> You have very well laid-out unit tests. This is great practice, but for the purposes of this project you can depend on \"trusting the math\" for simple expressions.\n",
    "\n",
    "To keep this simple (and because of Joss' advice on my Project 2), I'll move all of the tests under validation to declutter the main section of the project.\n",
    "\n",
    "> While your printed trees are a great debug tool, they're a bit cluttered to be included in their entirety in your writeup. They're definitely closer to debugging text, and it isn't very useful for the reader to interpret the larger ones. Maybe leave a small example at most.\n",
    "\n",
    "Yeah, probably a good idea. I'll remove the longer ones.\n",
    "\n",
    "> Not sure how I feel about using ChatGPT to write unit tests...\n",
    "\n",
    "If it works, it works. I'd be shot for doing something like that in a computer science class. Thank god it isn't my major."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b5019a",
   "metadata": {},
   "source": [
    "> While your code and description of its implementation is great, this currently almost feels like the main purpose of your writeup rather than the investigation you should be carrying out for Project 3.\n",
    "\n",
    "> Your project almost immediately launches into a technical review of code... without giving the reader any of the necessary context (what is a monte carlo simulation? what is the physical scenario you are investigating? how are you modeling your system?) to properly follow it. Imagine your writeup as a lab report. Prior to making any nontrivial calculations in your \"Methods\" section, you would want to first introduce the relevant formalism and equations you are working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef22a27",
   "metadata": {},
   "source": [
    "> Fig2/3: There seems to be a misconception of what $k$ is. You should treat $k$ as a macroscopic constant intrinsic to a given test structure - not neutrons. By performing this Monte Carlo simulation, you are ultimately trying to compute the best possible \"measurement\" of k by averaging out the statistically-distributed results of many \"experimental\" simulations.\n",
    "\n",
    "> If your k values appear to still change significantly across generations (e.g. in Fig2), what does this tell you about the accuracy of your current measurement? How can you ensure this value of k has stabilized before taking a measurement? Try running your simulation for additional generations and plotting k vs generation number. Consider the relative uncertainty of your average k measurements in Figures 3--4. Does this change with volume and aspect ratio?\n",
    "\n",
    "> You need a much more thorough discussion of the uncertainties in your data and their implications on how you can interpret your results. Is 20--40 replications enough to average out statistical differences in this case? You are also making a lot of assertions about global minima and maxima in your case studies without actually modeling the data you are working with.\n",
    "\n",
    "> Beyond your heatmaps, the majority of your project focuses more on the properties of the process we are modeling rather than a study of system behavior vs your independent variables. You should perform a thorough and ideally quantitative analysis of how k scales with volume and aspect ratio. One way to do this is to fit cross-sections of your heat map data to a model of your devising.\n",
    "\n",
    "> Appendix: While it's great that you discuss the various validation and unit-testing techniques used to develop your project, you should also include some concrete and followable instances of code validation. An example of something you could check here is whether or not your neutron population behaves as expected for a given multiplication factor.\n",
    "\n",
    "> I'm unsure if your current experiment and its results generalize well enough to assert that a sphere would be ideal. What additional testing could you do to solidify this claim?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42cfdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
