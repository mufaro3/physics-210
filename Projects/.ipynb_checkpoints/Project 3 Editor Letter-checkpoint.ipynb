{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a46120f",
   "metadata": {},
   "source": [
    "Dear Allen Zhao,\n",
    "\n",
    "Thank you for your feedback on my Project 3 submission. Here are my responses. I hope that they are sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf7782",
   "metadata": {},
   "source": [
    "> This is quite a deviation from the array-based Monte Carlo framework we introduced in class. If you are intent on using this, I would like to see a straightforward comparison with the method we've laid out for you which makes it clear that your implementation is equivalent and robust enough for the purposes of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51480648",
   "metadata": {},
   "source": [
    "I spoke to Joss about this. I understand your concern, but I'm completely unsure what you mean by the \"array-based ... method we've laid out for you,\" as I never followed any sort of tutorial or outline for performing this project.  The starter code for this project (such as Homework 17) doesn't include a full process for this and Homework 16 isn't immediately applicable for these kinds of trees, so I'm not sure what you want me to compare against (as I've been using tree generation from the beginning of Homework 17). With that, Joss simply told me to ignore this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9fce0",
   "metadata": {},
   "source": [
    "> One major concern I have is that you are currently only modeling 3--4 generations of neutrons, which might not be enough to give statistically sound results (you need to verify this). If you end up needing to iterate over many more generations, I am not sure how performant an exponentially-growing tree of Python objects will be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d40a4a7",
   "metadata": {},
   "source": [
    "Honestly, you're right. I spoke to Joss about this as well, and the solution I've come to is that I could refocus my project to model long-run stable $k$ values and produce a singular contour, and this would require determining the maximum generation depth required for a system to be stable across all of the systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9bda57",
   "metadata": {},
   "source": [
    "> You have very well laid-out unit tests. This is great practice, but for the purposes of this project you can depend on \"trusting the math\" for simple expressions.\n",
    "\n",
    "To keep this simple (and because of Joss' advice on my Project 2), I'll move all of the tests under validation to declutter the main section of the project.\n",
    "\n",
    "> While your printed trees are a great debug tool, they're a bit cluttered to be included in their entirety in your writeup. They're definitely closer to debugging text, and it isn't very useful for the reader to interpret the larger ones. Maybe leave a small example at most.\n",
    "\n",
    "Yeah, this is probably a good idea. I'll remove the longer ones, and just keep the example.\n",
    "\n",
    "> Not sure how I feel about using ChatGPT to write unit tests...\n",
    "\n",
    "I'm only using it for tests where I need to verify very basic things (like the shape of output vectors and whatnot), so the code for doing it is tedious rather than complex. If it works, it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66279425",
   "metadata": {},
   "source": [
    "> While your code and description of its implementation is great, this currently almost feels like the main purpose of your writeup rather than the investigation you should be carrying out for Project 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdeafd7",
   "metadata": {},
   "source": [
    "Honestly, you are right, and I feel as though the best way to rectify this is to apply the additions to the introduction that you request in your next point alongside some deeper consideration sprinkled throughout the document. This message is a bit vague (in comparison to your next point about the introduction) so I'm going to take the liberty of just assuming that the most critical areas to increase the level of specificity will still remain at the investigative sections (so the strictly technical sections, such as function definitions, will remain mostly just technical descriptions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e9cfa",
   "metadata": {},
   "source": [
    "> Your project almost immediately launches into a technical review of code... without giving the reader any of the necessary context (what is a monte carlo simulation? what is the physical scenario you are investigating? how are you modeling your system?) to properly follow it. Imagine your writeup as a lab report. Prior to making any nontrivial calculations in your \"Methods\" section, you would want to first introduce the relevant formalism and equations you are working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd15f06",
   "metadata": {},
   "source": [
    "To begin, I'm going to address this point by considering each of the questions that you're explicitly asking here one-by-one, and then I'll use my answers to each of those questions to produce the basis statement that you're asking for as one succinct description.\n",
    "\n",
    "> What is a Monte Carlo Simulation?\n",
    "\n",
    "A Monte Carlo simulation is a general class of stochastic (random) methods for performing computational calculations. In this case, we're calculating a value through performing a high volume of random simulations to produce a distribution of values (multiplication rates), then selecting the mean and standard error of that distribution to act as the final calculation of the value.\n",
    "\n",
    "> What is the physical scenario you are investigating? / How are you modelling your system?\n",
    "\n",
    "Consider the core of a nuclear reactor. Neutrons are, obviously, much smaller than the gaps between atoms and their neutral charge causes them to not have attractive force to free electrons or any repellant force, meaning that they can fairly easily escape the metallic bounds of reactor cores once atoms are split through fission. Therefore, it's fairly accurate to model the neutrons in a reactor as having no physical bounds whatsoever (in the form of a potential field blocking them from leaving), and this simulation seeks to investigate how often neutrons continue to replicate within this reactor.\n",
    "\n",
    "As a nuclear reaction progresses, Neutrons \"replicate\" into several more by triggering further fission reactions in other atoms, and the amount of Neutrons that are produced from the presence of previous Neutron are "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be004113",
   "metadata": {},
   "source": [
    "> Fig2/3: There seems to be a misconception of what $k$ is. You should treat $k$ as a macroscopic constant intrinsic to a given test structure - not neutrons. By performing this Monte Carlo simulation, you are ultimately trying to compute the best possible \"measurement\" of k by averaging out the statistically-distributed results of many \"experimental\" simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18479e6",
   "metadata": {},
   "source": [
    "I understand what you mean. I think the major error in my work is in Figure 2 with the line \"The first generation can only ever replicate 0, 1, or 2 neutrons exactly, so an individual neutron $i$ will have exactly $k_i = 0, 1, 2$: a discrete range. So, in short, because the range of possible $k$ values for a given neutron is so limited, the negative contribution from low $k$ values will be much higher.\" and in figure 3, with the line \"The first generation will usually have a replication rate of $k=2$ or $k=1$\". I think the best remedy for this is just switching the entire project to use long-run $k$-values, as stated previously. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce08eb1",
   "metadata": {},
   "source": [
    "> If your k values appear to still change significantly across generations (e.g. in Fig2), what does this tell you about the accuracy of your current measurement? How can you ensure this value of k has stabilized before taking a measurement? Try running your simulation for additional generations and plotting k vs generation number. Consider the relative uncertainty of your average k measurements in Figures 3--4. Does this change with volume and aspect ratio?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47b3d4",
   "metadata": {},
   "source": [
    "> You need a much more thorough discussion of the uncertainties in your data and their implications on how you can interpret your results. Is 20--40 replications enough to average out statistical differences in this case? You are also making a lot of assertions about global minima and maxima in your case studies without actually modeling the data you are working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a545335",
   "metadata": {},
   "source": [
    "> Beyond your heatmaps, the majority of your project focuses more on the properties of the process we are modeling rather than a study of system behavior vs your independent variables. You should perform a thorough and ideally quantitative analysis of how k scales with volume and aspect ratio. One way to do this is to fit cross-sections of your heat map data to a model of your devising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f4947",
   "metadata": {},
   "source": [
    "> Appendix: While it's great that you discuss the various validation and unit-testing techniques used to develop your project, you should also include some concrete and followable instances of code validation. An example of something you could check here is whether or not your neutron population behaves as expected for a given multiplication factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3444cc",
   "metadata": {},
   "source": [
    "> I'm unsure if your current experiment and its results generalize well enough to assert that a sphere would be ideal. What additional testing could you do to solidify this claim?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3e83f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dfaacfa",
   "metadata": {},
   "source": [
    "I hope that this is good enough! Thanks again for the notes, and thank you for the great term.\n",
    "\n",
    "Regards,\n",
    "\n",
    "Mufaro Machaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76e961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
