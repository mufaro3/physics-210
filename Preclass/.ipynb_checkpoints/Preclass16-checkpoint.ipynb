{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preclass Assignment: Day 16 (Oct 29, 2025)<br>Fitting\n",
    "Learning goals\n",
    "1. Use the scatter operator `*` when calling a function\n",
    "1. Use `scipy.optimize.curve_fit` to fit a model to an x-y data set and extract the fitting parameters\n",
    "1. Use extracted fitting parameters to plot the best fit model\n",
    "1. Extract uncertainties from fitting parameters\n",
    "1. Include absolute y-data uncertainties in the fit\n",
    "1. Make good initial guesses of the fitting parameters to improve the chance that the real best fit will be found instead of a local minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *No self-assessment questions for this reading*\n",
    "\n",
    "Although you have likely interacted with many of these concepts in Physics 219 and elsewhere, we're presenting some of the details in different ways that you may have encountered so would like everybody to work their way through this notebook. There are some Your Turn questions embedded throughout to help you test your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Fitting with `scipy.optimize.curve_fit`*\n",
    "\n",
    "The main fitting routine that we will use in this course is the `scipy` fitting routine `curve_fit()`. You can read more about it at:\n",
    "    \n",
    "* http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\n",
    "\n",
    "This fitting routine uses non-linear least squares fitting. For those of you that took Physics 119, this is the same as minimizing chi-squared by minimizing the sum of the residuals squared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _1. The scatter operator `*`_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before discussing `scipy.optimize.curve_fit`, we need to first discuss using the `*` operator with arguments when calling a function. When used this way it is called the scatter or splat operator. It is used to unpack a container (such as a list, tuple or array) into its individual elements---as *positional arguments*---when passing this argument to a function.\n",
    "\n",
    "Let's first look at a typical function call with three arguments. The code below shows a function that sums three numbers. If those three numbers were in a list, we could index each individual number when we call the function, as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def sum_of_three_numbers(a, b, c):\n",
    "    return a + b + c\n",
    "\n",
    "# The list of numbers\n",
    "numbers = [1, 2, 3]\n",
    "\n",
    "# Call the function using indexing to pass each individual number\n",
    "mysum = sum_of_three_numbers(numbers[0], numbers[1], numbers[2])\n",
    "\n",
    "# Print the result\n",
    "print(mysum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can put the scatter operator in front of our list (i.e., `*numbers`) when we call our function. What this does is unpacks the list `numbers` into the individual elements `numbers[0]`, `numbers[1]` and `numbers[2]` and then passes those to the function. We will see that this is very handy when we use of best-fit parameters to plot our model functions when using `scipy.optimize.curve_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Call the function using our 'numbers' list directly thanks to the scatter operator\n",
    "mysum = sum_of_three_numbers(*numbers)\n",
    "\n",
    "print(mysum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following code. Which line would cause an error, and why?\n",
    "```python\n",
    "def subtract(a, b, c):\n",
    "    return a - b - c\n",
    "\n",
    "args1 = [5, 3]\n",
    "args2 = [5, 3, 1]\n",
    "\n",
    "result1 = subtract(*args1)\n",
    "result2 = subtract(*args2)\n",
    "```\n",
    "A) `result1 = subtract(*args1)` will cause an error because args1 has two elements.<br>\n",
    "B) `result1 = subtract(*args1)` will cause an error because args1 is a list.<br>\n",
    "C) `result2 = subtract(*args2)` will cause an error because args2 has three elements.<br>\n",
    "D) `result2 = subtract(*args1)` will cause an error because args2 is a list.<br>\n",
    "E) More than one of the above are true.<br>\n",
    "F) None of the lines will cause an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code testing area to help answer this question\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer A is correct\n"
     ]
    }
   ],
   "source": [
    "# Enter your answer inside the string quotes and run this cell to check your anwer\n",
    "\n",
    "answer = \"A\"\n",
    "\n",
    "import hashlib\n",
    "assert answer in ['A', 'B', 'C', 'D', 'E', 'F'], \"Your answer did not match any of the choices\"\n",
    "assert hashlib.sha256(answer.encode()).hexdigest() == \\\n",
    "    '559aead08264d5795d3909718cdd05abd49572e84fe55590eef31a88a08fdffd', \"Your answer is incorrect\"\n",
    "print(\"Your answer\", answer, \"is correct\") # Passed all assert statements above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *2. An initial linear fit, <u>without</u> uncertainties*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide a data set that we are going to try to mode using a straight line, $y=mx+b$. \n",
    "\n",
    "First, let's plot these data so we have a sense of what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = np.array([.04, .06, .08, .1 , .13, .15])\n",
    "y_data = np.array([3.14, 3.89, 4.04, 4.33, 4.67, 5.08])\n",
    "yerror = np.array([0.52, 0.22, 0.53, 0.53, 0.24, 0.54])\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=yerror, fmt = \"bo\", capsize=5)\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look plausbily linear. Based on some quick mental math, we can get initial estimates of the slope and y-intercept for this data set. \n",
    "\n",
    "Ignoring uncertainties for now, we can notice that the data show a rise of approximately 2 units ($\\approx 5-3$) over a run of approximately 0.1 units ($\\approx 0.14-0.04$). Thus the slope is approximately $2/0.1 \\approx 20$. A reasonable estimate for the y-intercept would be $\\approx 2.0 \\mbox{ units}$.\n",
    "\n",
    "Let's run the fit and double-check that the results make some sense. \n",
    "\n",
    "**Important!** Although our data do have y-uncertainties, we won't use them yet with `curve_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows us to use scipy's 'optimize.curve_fit'\n",
    "from scipy import optimize\n",
    "\n",
    "# Like with solve_ivp, we need to define a function that curve_fit will interact with\n",
    "# - The first parameter will always be the x variable\n",
    "# - The subsequent parameters will be our parameters for our fitting function\n",
    "# - Finally, we return what this function would calculate our y value to be\n",
    "#   so that curve_fit can compare it to y_data\n",
    "def line(x, m, b):\n",
    "    return m*x + b\n",
    "\n",
    "# curve_fit returns a tuple consisting of\n",
    "# - An array of our best-fit parameters, which we call fitparams\n",
    "# - A covariance matrix (fitcov) from which we can extract the uncertainties in our\n",
    "#   best-fit parameters.\n",
    "fitparams, fitcov = optimize.curve_fit(line, x_data, y_data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"m = {fitparams[0]:.1f};  b = {fitparams[1]:.2f}\")\n",
    "\n",
    "# The diagnonal of the covariance matrix gives the variance (standard deviation squared)\n",
    "# of our fitting parameters and the off-diagnonals communicate the correlations between\n",
    "# our fitting parameters. To get the uncertainty in each fitting parameter, we need to take\n",
    "# the square root of the variance.\n",
    "#\n",
    "# Important! Since we are not yet using the data y-uncertainties in our fit, these\n",
    "# uncertainties in δm and δb are mostly meaningless at this point.\n",
    "#\n",
    "dfitparams = np.sqrt(np.diag(fitcov))\n",
    "print(f\"δm = {dfitparams[0]:.2};  δb = {dfitparams[1]:.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that our initial estimates of these parameters (`m = 20`, `b = 2`) were somewhat reasonable, but were more that one standard deviation away from the actual results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's graph the results.**\n",
    "\n",
    "In the code below we will use our previously defined function `line()`, but here we will use the scatter operator `*` (e.g., `yf = line(xf, *fitparams)`) to pass all of our fit parameters using a very concise line of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's plot the best fit line\n",
    "\n",
    "# To produce a smooth curve, we need to produce a large number x values over the data\n",
    "# range, and can then determine the corresponding y values using our line function\n",
    "xf = np.linspace(x_data.min(), x_data.max(), num = 200)\n",
    "\n",
    "# We re-use our `line` function from before. We use \"*fitparams\", which is automatically\n",
    "# unpacked it into fitparams[0] and fitparams[1] when passed to the line() function\n",
    "yf = line(xf, *fitparams)\n",
    "\n",
    "# Plot the data again\n",
    "plt.errorbar(x_data, y_data, yerr=yerror, fmt = \"bo\", capsize=5, label=\"Data\")\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('y values')\n",
    "\n",
    "# Add the best fit line\n",
    "plt.plot(xf, yf, \"r-\", label=\"Best-fit line (ignoring uncertainties)\")\n",
    "\n",
    "# Add a grid and legend and show then show the entire plotting canvas\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to incorporate the y-uncertainties from our into our fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *3. Including uncertainties in our fit*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use two optional arguments to communicate to `curve_fit` that we want it to use the data y-uncertainties in our fit. This will use the most common physics approach of weighting each data point by 1/yerror<sup>2</sup>. \n",
    "1. Our first optional argument is `sigma = yerror`, which tells `curve_fit` that our \"one sigma\" errors are stored as `yerror`. \n",
    "2. Our second optional argument is `absolute_sigma = True`, which tells `curve_fit` to treat these as absolute errors, which is how we are plotting them. If set to `False` or not specified, `curve_fit` will treat these as relative errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can re-use our previous `line` function so just need to call `curve_fit` with\n",
    "# our new optional arguments\n",
    "\n",
    "fitparams2, fitcov2 = optimize.curve_fit(line, x_data, y_data, sigma = yerror, absolute_sigma = True)\n",
    "\n",
    "dfitparams2 = np.sqrt(np.diag(fitcov2))\n",
    "\n",
    "print(f\"m = {fitparams2[0]:.1f};  b = {fitparams2[1]:.2f}\")\n",
    "print(f\"δm = {dfitparams2[0]:.2};  δb = {dfitparams2[1]:.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our results. \n",
    "\n",
    "Note that since we previously created the array `xf` to help us with plotting our best-fit lines, we can use `xf` and our new fitting parameters `fitparams2` to determine the y-values for this new fit, `yf2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the y-values of our updated fit\n",
    "yf2 = line(xf, *fitparams2)\n",
    "\n",
    "# Plot the data\n",
    "plt.errorbar(x_data, y_data, yerr=yerror, fmt = \"bo\", capsize=5, label=\"Data\")\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('y values')\n",
    "\n",
    "# Plot the old best fit line\n",
    "plt.plot(xf, yf, \"r-\", label=\"Fit (ignoring uncertainties)\")\n",
    "\n",
    "# ...and the new best fit line\n",
    "plt.plot(xf, yf2, \"g--\", label=\"Fit (including uncertainties)\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the including `yerror` in the fit as absolute errors results in a fit that gives much more weight to the two data points with small uncertainties, as shown by the dashed green line having a lower slope and passing much more closely to the middle of those two data points with small uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, why do we include `absolute_sigma = True`?\n",
    "\n",
    "```python\n",
    "fitparams2, fitcov2 = optimize.curve_fit(line, x_data, y_data, sigma = yerror, absolute_sigma = True)\n",
    "```\n",
    "\n",
    "A) To ensure that the `sigma = yerror` values are interpreted as relative errors rather than absolute errors.<br>\n",
    "B) To ensure that the `sigma = yerror` values are interpreted as absolute errors rather than relative errors.<br>\n",
    "C) To normalize the `y_data` values before fitting the curve.<br>\n",
    "D) To constrain the parameters so that they stay within certain bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code testing area to help answer this question\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer inside the string quotes and run this cell to check your anwer\n",
    "\n",
    "answer = \"\"\n",
    "\n",
    "import hashlib\n",
    "assert answer in ['A', 'B', 'C', 'D'], \"Your answer did not match any of the choices\"\n",
    "assert hashlib.sha256(answer.encode()).hexdigest() == \\\n",
    "    'df7e70e5021544f4834bbee64a9e3789febc4be81470df629cad6ddb03320a5c', \"Your answer is incorrect\"\n",
    "print(\"Your answer\", answer, \"is correct\") # Passed all assert statements above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4. Extracting fitting parameter uncertainties*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to understand a bit better how we have been extracting the fitting parameter uncertainties `δm` and `δb` in our previous calls to `curve_fit`.\n",
    "\n",
    "First, let's repeat our most recent fit. Be reminded that `curve_fit` returns two arrays, which we assign to `fitparams2` and `fitcov2` in this example.\n",
    "\n",
    "1. `fitparams2` (called `popt` in the `curve_fit` documentation) returns a 1D array of the optimal values of the parameters resulting from minimization of the sum of the squared residuals. In our example, `fitparams2[0]` gives us `m` and `fitparams2[1]` gives us `b`.<br><br>\n",
    "1. `fitcov2` (called `pcov` in the `curve_fit` documentation) returns a 2D array where the diagnonal of the covariance matrix gives the variance (standard deviation squared) of our fitting parameters and the off-diagnonals communicate the correlations between our fitting parameters. \n",
    "   * This means we need to first extract the diagonal of this 2D array and then take the square root. This will give a 1D array of the uncertainties in our fitting parameters. We do this in smaller steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitparams2, fitcov2 = optimize.curve_fit(line, x_data, y_data, sigma = yerror, absolute_sigma = True)\n",
    "\n",
    "print(\"The covariance matrix fitcov2:\\n\", fitcov2)\n",
    "\n",
    "print(\"\\nThe diagonal of fitcov2:\\n\", np.diag(fitcov2))\n",
    "\n",
    "# This gives the uncertainties in our fitting parameters given by fitparams2\n",
    "print(\"\\nThe squareroot of the diagonal of fitcov2:\\n\", np.sqrt(np.diag(fitcov2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *5. Initial guesses for fitting parameters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of least-squares fitting involves looking for a minumum in the sum of the residuals squared, where a residual is the distance between a data point and the value predicted by the model for that data point. Models will have an absolute minimum value chi-squared, corresponding to the best possible fit of that model to those data, **but many models will also have many local minima**. This means that `curve_fit` may find a solution that minimizes the sum of the residuals squared as compared to nearby variations of the solution parameters, but which is not absolute minimum. Let's take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load some initial data and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "t_data = np.array([ 0.        ,  0.25645654,  0.51291309,  0.76936963,  1.02582617,\n",
    "        1.28228272,  1.53873926,  1.7951958 ,  2.05165235,  2.30810889,\n",
    "        2.56456543,  2.82102197,  3.07747852,  3.33393506,  3.5903916 ,\n",
    "        3.84684815,  4.10330469,  4.35976123,  4.61621778,  4.87267432,\n",
    "        5.12913086,  5.38558741,  5.64204395,  5.89850049,  6.15495704,\n",
    "        6.41141358,  6.66787012,  6.92432667,  7.18078321,  7.43723975,\n",
    "        7.69369629,  7.95015284,  8.20660938,  8.46306592,  8.71952247,\n",
    "        8.97597901,  9.23243555,  9.4888921 ,  9.74534864, 10.00180518,\n",
    "       10.25826173, 10.51471827, 10.77117481, 11.02763136, 11.2840879 ,\n",
    "       11.54054444, 11.79700098, 12.05345753, 12.30991407, 12.56637061])\n",
    "y_data = np.array([-1.71815239e-03, -2.08015913e-01,  5.64748219e-01,  9.62492904e-01,\n",
    "        9.20418866e-01,  9.35737259e-01,  1.32776675e+00,  1.58956031e+00,\n",
    "        1.88558979e+00,  1.66143882e+00,  2.03767118e+00,  2.25638778e+00,\n",
    "        2.00445035e+00,  2.04773244e+00,  2.17685040e+00,  1.88546903e+00,\n",
    "        1.81505858e+00,  1.48373884e+00,  1.59274906e+00,  1.57320479e+00,\n",
    "        9.91393316e-01,  1.08707412e+00,  7.51733967e-01, -4.56799784e-02,\n",
    "       -3.91397237e-01, -1.96417994e-01, -2.74839190e-01, -4.23692135e-01,\n",
    "       -7.91822825e-01, -1.31857939e+00, -1.12749963e+00, -1.84915218e+00,\n",
    "       -1.90104185e+00, -2.06498665e+00, -1.90021998e+00, -1.85630497e+00,\n",
    "       -2.16964289e+00, -2.38494504e+00, -1.79373814e+00, -1.84252623e+00,\n",
    "       -1.61829111e+00, -1.70084067e+00, -1.63726353e+00, -1.41318373e+00,\n",
    "       -1.14480241e+00, -1.20080281e+00, -9.50884586e-01, -8.69321294e-01,\n",
    "       -1.45618763e-01, -2.32657944e-01])\n",
    "\n",
    "plt.scatter(t_data, y_data, s=10, label='Data')\n",
    "plt.xlabel('t values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're expecting these data to be described by the model \n",
    "\n",
    "$$a \\sin{\\omega t}.$$\n",
    "\n",
    "Like we did previously, we can generate some initial estimates of the fitting parameters by knowing the model function and inspecting the behaviour of the data. \n",
    "* Since this is a sin wave, we can observe a reasonably obvious amplitude of approximately 2, allowing us to set our initial guess of the related term to $a = 2$. \n",
    "* We can also see that it takes approximately 12 time units to go through one full period. Knowing that the relationship between period and angular frequency is $\\omega = 2\\pi/T$, this gives us an estimate of $\\omega \\approx 2\\pi/12 \\approx 0.5$. Let's keep these values in mind as we proceed with this fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have developed some good initial guesses for the fitting parameters, **let's first perform a fit without providing any initial guesses for our fitting parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sum of sine waves function\n",
    "def sin_model(x, a, omega):\n",
    "    return a * np.sin(omega * x)\n",
    "\n",
    "# Fit with no initial guess\n",
    "popt_no_guess, pcov_no_guess = curve_fit(sin_model, t_data, y_data)\n",
    "\n",
    "# Print the \"no guess\" best fit parameters\n",
    "print(f\"a = {popt_no_guess[0]:.3};  omega = {popt_no_guess[1]:.3}\")\n",
    "\n",
    "# Generate our graphs\n",
    "plt.scatter(t_data, y_data, s=10, label='Data')\n",
    "plt.plot(t_data, sin_model(t_data, *popt_no_guess), 'r-', label='Fit (no initial guess)')\n",
    "plt.xlabel('t values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WHAT THE WHAT?!?!?! Why did this fail so spectacularly?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`curve_fit` requires initial guesses for each parameter and if it does not receive any initial guesses, it provides default values of `1` for each parameter.\n",
    "\n",
    "In the code we did not provide any initial guesses so it used its default values of `1`. Why is this a problem?\n",
    "\n",
    "Well, `curve_fit` starts the fitting process with a model using values that correspond to the predictions made according to the initial guesses for the parameters. Since we didn't specify our initial guesses, it used default values of `a = 1` and `omega = 1`. After starting with these initial parameter guesses, it varies these parameters slowly while monitoring the sum of residuals squared to determine when it has found a minimum chi-squared. \n",
    "\n",
    "The code below builds a graph of chi-squared vs various omega values, ranging from `omega = 0.1 - 2.0`, while holding the amplitude fixed at `a = 1`. On the graph we see a nice deep minimum in chi-squared correspoding to `omega = 0.48`, but we also notice that there is another \"local\" minumum around `omega = 1.1`. \n",
    "\n",
    "Since we started with the default initial guess of `omega = 1`, the `curve_fit` function found that increasing `omega` reduced chi-squared and then it fell into a local minimum at `omega = 1.1`, where neither increasing nor decreasing `omega` improved chi-squared further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chi-squared calculation function\n",
    "def get_chi2(p0):\n",
    "    residuals = y_data - sin_model(t_data, *p0)\n",
    "    return sum(residuals**2) / (len(y_data) - 2)\n",
    "\n",
    "# Set up omega values and empty chi2_vals\n",
    "omega_vals = np.linspace(0.1, 2.0, 100)\n",
    "chi2_vals = np.empty_like(omega_vals)\n",
    "\n",
    "# Fixed parameter 'a'\n",
    "a = 1\n",
    "\n",
    "# Calculate chi-squared values for each omega\n",
    "for i, omega in enumerate(omega_vals):\n",
    "    p = (a, omega)\n",
    "    chi2_vals[i] = get_chi2(p)\n",
    "\n",
    "# Find the global minimum chi-squared and its corresponding omega\n",
    "global_min_chi2 = np.min(chi2_vals)\n",
    "global_min_omega = omega_vals[np.argmin(chi2_vals)]\n",
    "\n",
    "# Find the local minimum chi-squared in the range omega = 1 to omega = 1.25\n",
    "mask = (omega_vals >= 1) & (omega_vals <= 1.25)\n",
    "restricted_chi2_vals = chi2_vals[mask]\n",
    "restricted_omega_vals = omega_vals[mask]\n",
    "local_min_chi2 = np.min(restricted_chi2_vals)\n",
    "local_min_omega = restricted_omega_vals[np.argmin(restricted_chi2_vals)]\n",
    "\n",
    "# Plot chi-squared values against omega\n",
    "plt.plot(omega_vals, chi2_vals, label='Chi-squared values', color = 'b')\n",
    "plt.scatter(global_min_omega, global_min_chi2, marker='o', \n",
    "            label=f'Global Minimum: ({global_min_omega:.2f}, {global_min_chi2:.2f})', color = 'b', s=60)\n",
    "plt.scatter(local_min_omega, local_min_chi2, marker='d', \n",
    "            label=f'Local Minimum: ({local_min_omega:.2f}, {local_min_chi2:.2f})', color = 'b', s=60)\n",
    "plt.xlabel('Omega')\n",
    "plt.ylabel('Chi-squared')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's use some slightly better initial guesses than `p0=[1, 1]`**\n",
    "\n",
    "For our initial guesses, let's use our estimates from the start of this section ($a\\approx 2$ and $\\omega \\approx 0.5$) as an optional argument to `curve_fit` using `p0=[2, 0.5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with an initial guess\n",
    "popt_guess, pcov_guess = curve_fit(sin_model, t_data, y_data, p0=[2, 0.5])\n",
    "\n",
    "# Plot\n",
    "plt.scatter(t_data, y_data, s=10, label='Data')\n",
    "plt.plot(t_data, sin_model(t_data, *popt_no_guess), 'r-', label='Fit (initial guess = [1, 1])')\n",
    "plt.plot(t_data, sin_model(t_data, *popt_guess), 'g-', label='Fit (initial guess = [2, 0.5])')\n",
    "plt.xlabel('t values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hopefully you can see the importance of initial guesses when fitting to nonlinear functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following exponential decay data, try to come up with your best initial guesses for the parameters `a`, `b` and `c`. \n",
    "\n",
    "1. The first code box plots the data. \n",
    "2. The second code box allows you to enter your best initial guesses for a, b and c. \n",
    "    * **Test them out to see how close the result is. Take some time to try to improve the match between the data and the curve described by your initial guesses for a, b and c.**\n",
    "3. Finally, run the code in the third code box to perform the fit using your initial guesses for the fitting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the exponential decay model\n",
    "def exponential_decay(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "x_data = np.linspace(0, 4, 25)\n",
    "y_data = np.array([3.69825186, 3.13012273, 2.64854927, 2.12150665, 1.93384329,\n",
    "       1.61788173, 1.42167637, 1.25036513, 0.9963676 , 0.98906286,\n",
    "       0.89092495, 0.73276012, 0.96662416, 0.7227811 , 0.75511437,\n",
    "       0.66954628, 0.52919564, 0.60806532, 0.5970682 , 0.49954995,\n",
    "       0.57694673, 0.54343057, 0.60835945, 0.43258547, 0.59508027])\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(x_data, y_data, label='Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these with your best guesses for a, b, c\n",
    "p0 = [1, 1, 1]\n",
    "\n",
    "# Plot the data and model\n",
    "plt.scatter(x_data, y_data, label='Data')\n",
    "plt.plot(x_data, exponential_decay(x_data, *p0), color='red', label='Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data\n",
    "fitparams, fitcov = optimize.curve_fit(exponential_decay, x_data, y_data, p0=p0)\n",
    "\n",
    "# Plot the data and the fit\n",
    "plt.scatter(x_data, y_data, label='Data')\n",
    "plt.plot(x_data, exponential_decay(x_data, *fitparams), color='red', label='Best fit model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Display optimized parameters\n",
    "print(\"Optimized parameters:\", fitparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Submitting this reading assignment*\n",
    "Before submitting your work, please ensure you have worked carefully through all the cells. Afterward choose: File >> Save_and_Export_Notebook_As >> HTML. This will download an HTML version of your notebook to your computer which you can upload to Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
